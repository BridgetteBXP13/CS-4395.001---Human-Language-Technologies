{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99efc4d5-23ba-4ec1-9dde-7ada72b63dfa",
   "metadata": {},
   "source": [
    "# Author Attribution\n",
    "\n",
    "In this notebook I will predict the author of a given text from federalist.csv. It is a csv file of text and it's given author whom can be Hamilton, Jay, or Madison. Sometimes a mixture of the authors as well. I will utlize pandas for the data processing, NLP for the word processing, and then sklearn to perform Bernoulli Naive Bayes, Logistic Regression, and Neural Network.\n",
    "\n",
    "## Reading and Processing the Data\n",
    "### With Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45b2f107-98d1-4787-9b5e-116bee55c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: \n",
      "HAMILTON                49\n",
      "MADISON                 15\n",
      "HAMILTON OR MADISON     11\n",
      "JAY                      5\n",
      "HAMILTON AND MADISON     3\n",
      "Name: author, dtype: int64\n",
      "\n",
      "First few rows of data frame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAMILTON</td>\n",
       "      <td>FEDERALIST. No. 1 General Introduction For the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JAY</td>\n",
       "      <td>FEDERALIST No. 2 Concerning Dangers from Forei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JAY</td>\n",
       "      <td>FEDERALIST No. 3 The Same Subject Continued (C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JAY</td>\n",
       "      <td>FEDERALIST No. 4 The Same Subject Continued (C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JAY</td>\n",
       "      <td>FEDERALIST No. 5 The Same Subject Continued (C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author                                               text\n",
       "0  HAMILTON  FEDERALIST. No. 1 General Introduction For the...\n",
       "1       JAY  FEDERALIST No. 2 Concerning Dangers from Forei...\n",
       "2       JAY  FEDERALIST No. 3 The Same Subject Continued (C...\n",
       "3       JAY  FEDERALIST No. 4 The Same Subject Continued (C...\n",
       "4       JAY  FEDERALIST No. 5 The Same Subject Continued (C..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Pandas\n",
    "import pandas as pd\n",
    "# Reading in the csv file with pandas\n",
    "df = pd.read_csv('federalist.csv')\n",
    "# Converting the author column to categorical data\n",
    "df.author = df.author.astype('category')\n",
    "# Displaying the counts of each author\n",
    "print(\"Counts: \")\n",
    "print(df.author.value_counts())\n",
    "# Displaying the first few rows of the data frame\n",
    "print(\"\\nFirst few rows of data frame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c89962-9bad-4817-9780-225c68576104",
   "metadata": {},
   "source": [
    "### Utilizing sklearn to create train/test data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1234a1e9-bbb7-4081-b2e1-2782e08aa1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train data:  (66,)\n",
      "Dimensions of test data:  (17,)\n"
     ]
    }
   ],
   "source": [
    "# Import sklearn's train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Divide into train and test (80/20 with seed 1234 for replicable results)\n",
    "# X contains the predictor columns and y contains the target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.text, df.author, test_size=0.2, random_state=1234,\n",
    "    stratify=df.author)\n",
    "\n",
    "# Outputting the dimensions of train and test\n",
    "print(\"Dimensions of train data: \", X_train.shape)\n",
    "print(\"Dimensions of test data: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9290cb6a-5183-427c-b292-4a1f7752e210",
   "metadata": {},
   "source": [
    "### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8ec949-374d-4a3a-a16e-ca74651778a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the nltk stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# This is our set of stopwords, it will be used during vectorization\n",
    "stopwords = set(stopwords.words('English'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc89ce-6916-4721-8287-44eefb72e218",
   "metadata": {},
   "source": [
    "### Performing tf-idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e149696-944c-4017-9822-356c4302a25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the vectorized train data:  (66, 7678)\n",
      "Dimensions of the vectorized test data:  (17, 7678)\n"
     ]
    }
   ],
   "source": [
    "# Importing our tf-idf vectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Setting up our stopwords for our vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "# Perform tf-idf vectorization and fit to training data\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "# Transforming the test data with the fitted tf-idf vectorization\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "# Outputting the dimensions of train and test\n",
    "print(\"Dimensions of the vectorized train data: \", X_train_vect.shape)\n",
    "print(\"Dimensions of the vectorized test data: \", X_test_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b512373-2548-4da4-9509-691cc01675ea",
   "metadata": {},
   "source": [
    "## Benoulli Naive Bayes\n",
    "\n",
    "### The First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d094b84a-aee6-43b6-92e9-f07a9a735db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Data:  0.803030303030303\n",
      "\n",
      "Results on testing data:\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 2  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 3  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            HAMILTON       0.59      1.00      0.74        10\n",
      "HAMILTON AND MADISON       0.00      0.00      0.00         1\n",
      " HAMILTON OR MADISON       0.00      0.00      0.00         2\n",
      "                 JAY       0.00      0.00      0.00         1\n",
      "             MADISON       0.00      0.00      0.00         3\n",
      "\n",
      "            accuracy                           0.59        17\n",
      "           macro avg       0.12      0.20      0.15        17\n",
      "        weighted avg       0.35      0.59      0.44        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Importing the Benoulli Naive Bayes model from sklearn\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Creating Benoulli Naive Bayes model\n",
    "b_nb_1 = BernoulliNB()\n",
    "b_nb_1.fit(X_train_vect, y_train)\n",
    "# Printing the accuracy on the training data\n",
    "print(\"Accuracy on Training Data: \", b_nb_1.score(X_train_vect, y_train))\n",
    "\n",
    "# Testing and evaluating\n",
    "b_nb_1_pred = b_nb_1.predict(X_test_vect)\n",
    "\n",
    "# Importing tools from sklearn for evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"\\nResults on testing data:\\n\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, b_nb_1_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, b_nb_1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6effd15-c2cf-4e30-ad2f-881b91f7c560",
   "metadata": {},
   "source": [
    "### Performing tf-idf Vectorization with Adjusted Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c746f4b-1be4-4c16-b86a-e9bf05a3e94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the vectorized train data:  (66, 1000)\n",
      "Dimensions of the vectorized test data:  (17, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Limiting the number of frequent words and adding bigrams\n",
    "# to improve vectorization for train and test\n",
    "# Importing our tf-idf vectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Setting up our maximum number of words as 1000\n",
    "# stopwords and bigrams for our vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords, max_features=1000, ngram_range=(1,2))\n",
    "# Perform tf-idf vectorization and fit to training data\n",
    "X_train_vect2 = vectorizer.fit_transform(X_train)\n",
    "# Transforming the test data with the fitted tf-idf vectorization\n",
    "X_test_vect2 = vectorizer.transform(X_test)\n",
    "# Outputting the dimensions of train and test\n",
    "print(\"Dimensions of the vectorized train data: \", X_train_vect2.shape)\n",
    "print(\"Dimensions of the vectorized test data: \", X_test_vect2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b0f9b-4a6e-4a5d-9d5a-fa124d4af968",
   "metadata": {},
   "source": [
    "### The Second Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e31494-f793-4b85-82be-0779a63094f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Data:  1.0\n",
      "\n",
      "Results on testing data:\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 0  0  1  0  1]\n",
      " [ 1  0  0  0  0]\n",
      " [ 2  0  0  0  1]]\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            HAMILTON       0.71      1.00      0.83        10\n",
      "HAMILTON AND MADISON       0.00      0.00      0.00         1\n",
      " HAMILTON OR MADISON       1.00      0.50      0.67         2\n",
      "                 JAY       0.00      0.00      0.00         1\n",
      "             MADISON       0.50      0.33      0.40         3\n",
      "\n",
      "            accuracy                           0.71        17\n",
      "           macro avg       0.44      0.37      0.38        17\n",
      "        weighted avg       0.63      0.71      0.64        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Creating Benoulli Naive Bayes model with different vectorization\n",
    "b_nb_2 = BernoulliNB()\n",
    "b_nb_2.fit(X_train_vect2, y_train)\n",
    "# Printing the accuracy on the training data\n",
    "print(\"Accuracy on Training Data: \", b_nb_2.score(X_train_vect2, y_train))\n",
    "\n",
    "# Testing and evaluating\n",
    "b_nb_2_pred = b_nb_2.predict(X_test_vect2)\n",
    "\n",
    "print(\"\\nResults on testing data:\\n\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, b_nb_2_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, b_nb_2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f3ed7-d24a-4b70-aa5a-a9b4155d3939",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "### With lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d364d7-62f8-443e-82c2-525eeef6088f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on testing data:\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 0  0  1  0  1]\n",
      " [ 0  0  0  1  0]\n",
      " [ 1  0  0  0  2]]\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            HAMILTON       0.83      1.00      0.91        10\n",
      "HAMILTON AND MADISON       0.00      0.00      0.00         1\n",
      " HAMILTON OR MADISON       1.00      0.50      0.67         2\n",
      "                 JAY       1.00      1.00      1.00         1\n",
      "             MADISON       0.67      0.67      0.67         3\n",
      "\n",
      "            accuracy                           0.82        17\n",
      "           macro avg       0.70      0.63      0.65        17\n",
      "        weighted avg       0.78      0.82      0.79        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Importing our Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Training our model, using lbfgs solver\n",
    "logreg1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1234, class_weight='balanced')\n",
    "logreg1.fit(X_train_vect2, y_train)\n",
    "\n",
    "# Testing and evaluating\n",
    "logreg1_pred = logreg1.predict(X_test_vect2)\n",
    "\n",
    "print(\"\\nResults on testing data:\\n\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, logreg1_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, logreg1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb366e3b-9282-4169-94a5-aa2345f03f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Data:  1.0\n",
      "\n",
      "Results on testing data:\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 0  0  1  0  1]\n",
      " [ 0  0  0  1  0]\n",
      " [ 1  0  0  0  2]]\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            HAMILTON       0.83      1.00      0.91        10\n",
      "HAMILTON AND MADISON       0.00      0.00      0.00         1\n",
      " HAMILTON OR MADISON       1.00      0.50      0.67         2\n",
      "                 JAY       1.00      1.00      1.00         1\n",
      "             MADISON       0.67      0.67      0.67         3\n",
      "\n",
      "            accuracy                           0.82        17\n",
      "           macro avg       0.70      0.63      0.65        17\n",
      "        weighted avg       0.78      0.82      0.79        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Training our model, using liblinear solver\n",
    "logreg2 = LogisticRegression(solver='liblinear', random_state=1234, class_weight='balanced', C=10)\n",
    "logreg2.fit(X_train_vect2, y_train)\n",
    "# Printing the accuracy on the training data\n",
    "print(\"Accuracy on Training Data: \", logreg2.score(X_train_vect2, y_train))\n",
    "\n",
    "# Testing and evaluating\n",
    "logreg2_pred = logreg2.predict(X_test_vect2)\n",
    "\n",
    "print(\"\\nResults on testing data:\\n\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, logreg2_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, logreg2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b3ee4-235c-434b-9d77-f30c382ddd4d",
   "metadata": {},
   "source": [
    "### With liblinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc5ce1e-9ea0-4d50-a1c6-ed92a5cb69e5",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "### Neural Network 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa56b73-aaf6-4bc8-90e8-29d00bedbb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on testing data:\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 2  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 3  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            HAMILTON       0.59      1.00      0.74        10\n",
      "HAMILTON AND MADISON       0.00      0.00      0.00         1\n",
      " HAMILTON OR MADISON       0.00      0.00      0.00         2\n",
      "                 JAY       0.00      0.00      0.00         1\n",
      "             MADISON       0.00      0.00      0.00         3\n",
      "\n",
      "            accuracy                           0.59        17\n",
      "           macro avg       0.12      0.20      0.15        17\n",
      "        weighted avg       0.35      0.59      0.44        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Importing the multiclassifier neural network from sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Train our model\n",
    "neural_net1 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(2,1), random_state=1234)\n",
    "neural_net1.fit(X_train_vect2, y_train)\n",
    "\n",
    "# Testing and evaluating\n",
    "neural_net1_pred = neural_net1.predict(X_test_vect2)\n",
    "\n",
    "print(\"\\nResults on testing data:\\n\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, neural_net1_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, neural_net1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da57a96-b524-4cd4-a7fa-6682f6a3642e",
   "metadata": {},
   "source": [
    "### Neural Network 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffd8456-46eb-42ab-9365-cebcc05367a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on testing data:\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0  0  0  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 0  0  0  0  2]\n",
      " [ 0  0  0  0  1]\n",
      " [ 0  0  0  2  1]]\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            HAMILTON       1.00      1.00      1.00        10\n",
      "HAMILTON AND MADISON       0.00      0.00      0.00         1\n",
      " HAMILTON OR MADISON       0.00      0.00      0.00         2\n",
      "                 JAY       0.00      0.00      0.00         1\n",
      "             MADISON       0.25      0.33      0.29         3\n",
      "\n",
      "            accuracy                           0.65        17\n",
      "           macro avg       0.25      0.27      0.26        17\n",
      "        weighted avg       0.63      0.65      0.64        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Importing the multiclassifier neural network from sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Train our model\n",
    "neural_net2 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(2), random_state=1234)\n",
    "neural_net2.fit(X_train_vect2, y_train)\n",
    "\n",
    "# Testing and evaluating\n",
    "neural_net2_pred = neural_net2.predict(X_test_vect2)\n",
    "\n",
    "print(\"\\nResults on testing data:\\n\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, neural_net2_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, neural_net2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e607f-82a7-478e-81d9-57bcb8e4efcf",
   "metadata": {},
   "source": [
    "### Neural Network 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c24389-fd6d-440d-aced-97f01cdf900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on testing data:\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  0  0  0  0]\n",
      " [ 0  1  0  0  0]\n",
      " [ 0  0  1  0  1]\n",
      " [ 0  0  0  0  1]\n",
      " [ 0  2  1  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            HAMILTON       1.00      1.00      1.00        10\n",
      "HAMILTON AND MADISON       0.33      1.00      0.50         1\n",
      " HAMILTON OR MADISON       0.50      0.50      0.50         2\n",
      "                 JAY       0.00      0.00      0.00         1\n",
      "             MADISON       0.00      0.00      0.00         3\n",
      "\n",
      "            accuracy                           0.71        17\n",
      "           macro avg       0.37      0.50      0.40        17\n",
      "        weighted avg       0.67      0.71      0.68        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bridg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Importing the multiclassifier neural network from sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Train our model\n",
    "neural_net3 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(1,1), random_state=1234)\n",
    "neural_net3.fit(X_train_vect2, y_train)\n",
    "\n",
    "# Testing and evaluating\n",
    "neural_net3_pred = neural_net3.predict(X_test_vect2)\n",
    "\n",
    "print(\"\\nResults on testing data:\\n\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, neural_net3_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, neural_net3_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04508e-05bd-46f7-ba56-08f6242929cf",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Overall, this task was very challenging to get a good accuracy as the data set is very small with only about 400 observations. \n",
    "\n",
    "Starting off with the inital Naive Bayes it only had a 59% accuracy which is quite poor. By limiting the number of words used by tf-idf to 1000 and adding bigrams, I was able to get a 71% accuracy. This accuracy isn't great but still a 10% improvement. \n",
    "\n",
    "Next, the initial Logistic Regression with solver lbfgs initially had the 59% accuracy as well, but adding the 'balanced' and 'multinomial' parameters made it jump to 82%. I think this is because our data set is very unbalanced, with majority of the targets being Hamilton as seen by the Naive Bayes predictions.\n",
    "\n",
    "Then the second Logistic Regression with solver liblinear was even more tricky to get the accuracy from 59% to 82%. This is because the 'balanced' parameter didn't help very much. I then utilized the C parameter which controls the normalization, the higher the C, the less normalization. This helped significantly and after trying a few values the highest accuracy was with C=10.\n",
    "\n",
    "Finally, the Neural Networks, the initally topology with (2,1) got the terrible accuracy of 59%. The second I tried to further simplify it to prevent overfitting by using topology (2) and it slightly helped but still only had an accuracy of 65%. Then in the final topology I attempted splitting the layer into to with topology (1,1) which gave me the highest accuracy of 71% for neural networks. This wasn't surprising that it didn't do as well as the logistic regression because neural networks typically need a lot more data and likely more balanced data to perform well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
