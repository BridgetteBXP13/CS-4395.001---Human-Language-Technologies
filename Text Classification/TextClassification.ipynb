{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOThZA5bOGA4r4WhlBTLKe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BridgetteBXP13/CS-4395.001---Human-Language-Technologies/blob/main/Text%20Classification/TextClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification\n",
        "\n",
        "In this notebook we decided to do text classification for job postings, based on details within the job postings description, salary, location, etc. We will classify the job posting as likely to be real or fake. This dataset can be found [here](https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction) on Kaggle."
      ],
      "metadata": {
        "id": "TzELOMgXrHmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Our Dataset\n",
        "\n",
        "Here we simply have to import pandas and use it's prewritten functions to read our .csv dataset into a pandas dataframe. Our dataset was from kaggle but I also stored it [here on Github](https://github.com/BridgetteBXP13/CS-4395.001---Human-Language-Technologies/blob/main/Text%20Classification/fake_job_postings.csv)."
      ],
      "metadata": {
        "id": "Yv7Sm6a1BWPY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gn1F78NFq2xj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "e9cc507a-1daa-48ed-9c6a-0e6125049256"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   job_id                                      title            location  \\\n",
              "0       1                           Marketing Intern    US, NY, New York   \n",
              "1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
              "2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
              "3       4          Account Executive - Washington DC  US, DC, Washington   \n",
              "4       5                        Bill Review Manager  US, FL, Fort Worth   \n",
              "\n",
              "  department salary_range                                    company_profile  \\\n",
              "0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n",
              "1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n",
              "2        NaN          NaN  Valor Services provides Workforce Solutions th...   \n",
              "3      Sales          NaN  Our passion for improving quality of life thro...   \n",
              "4        NaN          NaN  SpotSource Solutions LLC is a Global Human Cap...   \n",
              "\n",
              "                                         description  \\\n",
              "0  Food52, a fast-growing, James Beard Award-winn...   \n",
              "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
              "2  Our client, located in Houston, is actively se...   \n",
              "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
              "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
              "\n",
              "                                        requirements  \\\n",
              "0  Experience with content management systems a m...   \n",
              "1  What we expect from you:Your key responsibilit...   \n",
              "2  Implement pre-commissioning and commissioning ...   \n",
              "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
              "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
              "\n",
              "                                            benefits  telecommuting  \\\n",
              "0                                                NaN              0   \n",
              "1  What you will get from usThrough being part of...              0   \n",
              "2                                                NaN              0   \n",
              "3  Our culture is anything but corporate—we have ...              0   \n",
              "4                              Full Benefits Offered              0   \n",
              "\n",
              "   has_company_logo  has_questions employment_type required_experience  \\\n",
              "0                 1              0           Other          Internship   \n",
              "1                 1              0       Full-time      Not Applicable   \n",
              "2                 1              0             NaN                 NaN   \n",
              "3                 1              0       Full-time    Mid-Senior level   \n",
              "4                 1              1       Full-time    Mid-Senior level   \n",
              "\n",
              "  required_education                   industry              function  \\\n",
              "0                NaN                        NaN             Marketing   \n",
              "1                NaN  Marketing and Advertising      Customer Service   \n",
              "2                NaN                        NaN                   NaN   \n",
              "3  Bachelor's Degree          Computer Software                 Sales   \n",
              "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
              "\n",
              "   fraudulent  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>title</th>\n",
              "      <th>location</th>\n",
              "      <th>department</th>\n",
              "      <th>salary_range</th>\n",
              "      <th>company_profile</th>\n",
              "      <th>description</th>\n",
              "      <th>requirements</th>\n",
              "      <th>benefits</th>\n",
              "      <th>telecommuting</th>\n",
              "      <th>has_company_logo</th>\n",
              "      <th>has_questions</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>required_experience</th>\n",
              "      <th>required_education</th>\n",
              "      <th>industry</th>\n",
              "      <th>function</th>\n",
              "      <th>fraudulent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Marketing Intern</td>\n",
              "      <td>US, NY, New York</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
              "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
              "      <td>Experience with content management systems a m...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Other</td>\n",
              "      <td>Internship</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Customer Service - Cloud Video Production</td>\n",
              "      <td>NZ, , Auckland</td>\n",
              "      <td>Success</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
              "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
              "      <td>What we expect from you:Your key responsibilit...</td>\n",
              "      <td>What you will get from usThrough being part of...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marketing and Advertising</td>\n",
              "      <td>Customer Service</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
              "      <td>US, IA, Wever</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Valor Services provides Workforce Solutions th...</td>\n",
              "      <td>Our client, located in Houston, is actively se...</td>\n",
              "      <td>Implement pre-commissioning and commissioning ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Account Executive - Washington DC</td>\n",
              "      <td>US, DC, Washington</td>\n",
              "      <td>Sales</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our passion for improving quality of life thro...</td>\n",
              "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
              "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
              "      <td>Our culture is anything but corporate—we have ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Computer Software</td>\n",
              "      <td>Sales</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Bill Review Manager</td>\n",
              "      <td>US, FL, Fort Worth</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
              "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
              "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
              "      <td>Full Benefits Offered</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Mid-Senior level</td>\n",
              "      <td>Bachelor's Degree</td>\n",
              "      <td>Hospital &amp; Health Care</td>\n",
              "      <td>Health Care Provider</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Importing pandas\n",
        "import pandas as pd\n",
        "# Reading in the data from csv from Github\n",
        "url = 'https://raw.githubusercontent.com/BridgetteBXP13/CS-4395.001---Human-Language-Technologies/main/Text%20Classification/fake_job_postings.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graphing our Categories\n",
        "\n",
        "Here we used pandas .hist() function to create a histogram. Then I customized it to make it took a bit nicer using ax, which is the axe object from MatPlotLib"
      ],
      "metadata": {
        "id": "BO25cWO1J1FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphs Showing Distribution\n",
        "ax = df.hist(column='fraudulent', bins=2, grid=False, figsize=(12,8),\n",
        "             color='#526CFF', zorder=2, rwidth=.9)\n",
        "ax = ax[0]\n",
        "\n",
        "for x in ax:\n",
        "\n",
        "  # Despine\n",
        "  x.spines['right'].set_visible(False)\n",
        "  x.spines['top'].set_visible(False)\n",
        "  x.spines['left'].set_visible(False)\n",
        "\n",
        "  # Switch off ticks\n",
        "  x.tick_params(axis='both', which='both', bottom=False, top=False, \n",
        "                labelbottom=False, left=False, right=False, labelleft=True)\n",
        "  \n",
        "  # Draw horizontal axis lines\n",
        "  x.set_yticks((0, 2500, 5000, 7500, 10000, 12500, 15000, 17500))\n",
        "  vals = x.get_yticks()\n",
        "  for tick in vals:\n",
        "    x.axhline(y=tick, linestyle='solid', alpha=None, color='#BDC7FF', zorder=1)\n",
        "\n",
        "  # Remove title\n",
        "  x.set_title(\"\")\n",
        "\n",
        "  # Set x-axis label\n",
        "  x.set_xlabel(\"Not Fraudulent                                                          Fraudulent\",\n",
        "               labelpad=20, weight='bold', size=12)\n",
        "\n",
        "  # Set y-axis label\n",
        "  x.set_ylabel(\"Number of Examples\")"
      ],
      "metadata": {
        "id": "QtA0mvYd2oB5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "bab11341-6f93-4673-f43c-7c60364bab40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About our Data\n",
        "\n",
        "Our dataset is designed to predict whether a job post is real (not fraudulent) or fake (fraudulent). For our purposes we will focus on the descriptions for text classification. Also many of the other columns have many missing values. As you can see from the graph above, there is a huge amount of real (not fraudulent) compared to fake (fraudulent). This is likely because most fake (fraudulent) job postings are taken down and are generally less common. Which makes them more difficult to collect. Having a large gap between our categories will pose a few challenges creating an accurate model.\n",
        "\n",
        "This dataset can be found [here](https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction) on Kaggle."
      ],
      "metadata": {
        "id": "WbGdXaDi8NYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Our Data\n",
        "\n",
        "### Splitting into Train, Test and Validate\n",
        "\n",
        "Here we use sklearn's train, test, and split function to create our train, test, and validate sets. To do this we first get the train and validate. Then we use the train data and use the function on it again to get our updated train and test. This way we get our validation, train, and test.\n",
        "\n",
        "### Vectorization\n",
        "\n",
        "Here we have to vectorize our data because our models will not take text directly as input. So we have to change our raw text into vectorized numbers to be model friendly. To do this we wrote a simple function to create a matrix given the shape and of specific shape."
      ],
      "metadata": {
        "id": "82GRz5cYLEMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some necessary packages\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = df[['description', 'fraudulent']]\n",
        "\n",
        "df.description = df.description.astype('str')\n",
        "df.fraudulent = df.fraudulent.astype('category')\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "np.random.seed(1234)\n",
        "i = np.random.rand(len(df)) < 0.8\n",
        "j = np.random.rand(len(df)) < 0.8\n",
        "train = df[i]\n",
        "test = df[~i]\n",
        "print(\"train data size: \", train.shape)\n",
        "print(\"test data size: \", test.shape)\n",
        "\n",
        "# set up X and Y\n",
        "num_labels = 2\n",
        "vocab_size = 25000\n",
        "batch_size = 100\n",
        "\n",
        "# fit the tokenizer on the training data\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(train.description)\n",
        "\n",
        "x_train = tokenizer.texts_to_matrix(train.description, mode='tfidf')\n",
        "x_test = tokenizer.texts_to_matrix(test.description, mode='tfidf')\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train.fraudulent)\n",
        "y_train = encoder.transform(train.fraudulent)\n",
        "y_test = encoder.transform(test.fraudulent)\n",
        "\n",
        "# check shape\n",
        "print(\"train shapes:\", x_train.shape, y_train.shape)\n",
        "print(\"test shapes:\", x_test.shape, y_test.shape)\n",
        "print(\"test first five labels:\", y_test[:5])"
      ],
      "metadata": {
        "id": "h-S8BJi7jX2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5954134f-5fed-40e4-911e-0fb14fbd9c95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         description fraudulent\n",
            "0  Food52, a fast-growing, James Beard Award-winn...          0\n",
            "1  Organised - Focused - Vibrant - Awesome!Do you...          0\n",
            "2  Our client, located in Houston, is actively se...          0\n",
            "3  THE COMPANY: ESRI – Environmental Systems Rese...          0\n",
            "4  JOB TITLE: Itemization Review ManagerLOCATION:...          0\n",
            "train data size:  (14342, 2)\n",
            "test data size:  (3538, 2)\n",
            "train shapes: (14342, 25000) (14342,)\n",
            "test shapes: (3538, 25000) (3538,)\n",
            "test first five labels: [0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Model\n",
        "\n",
        "### Creating our Sequential Model\n",
        "\n",
        "This model was created using Tensorflow's keras by getting a Sequential model object. Then we add multiple layers sequentially. (Hense the name Sequential)"
      ],
      "metadata": {
        "id": "P_NGooY0L8XQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "PrRKw9S9wd3w"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile our Sequential Model\n",
        "\n",
        "Then we simply use the compile the model using the compile funcion with given optimizer, loss, and metrics."
      ],
      "metadata": {
        "id": "yFO9JeIhMayT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xHRvcbcB21bx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training our Sequential Model\n",
        "\n",
        "We train our model using the .fit function giving it our train and validation data. We have to specify the batch size and number of epochs we want. Typically you can play with these numbers to adjust them for higher accuracy and to avoid underfitting/overfitting."
      ],
      "metadata": {
        "id": "JtRVihRlM2ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, \n",
        "                    y_train, \n",
        "                    epochs=20, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=1, \n",
        "                    validation_split=.1)"
      ],
      "metadata": {
        "id": "R0uUUa5ZNOVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ac9661-93d0-41b5-b50b-a7bea88b7ed7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.2040 - accuracy: 0.9468 - val_loss: 0.4171 - val_accuracy: 0.8105\n",
            "Epoch 2/20\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.0658 - accuracy: 0.9765 - val_loss: 0.3833 - val_accuracy: 0.8718\n",
            "Epoch 3/20\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.4789 - val_accuracy: 0.8941\n",
            "Epoch 4/20\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.5370 - val_accuracy: 0.8934\n",
            "Epoch 5/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.6400 - val_accuracy: 0.8976\n",
            "Epoch 6/20\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.7462 - val_accuracy: 0.8948\n",
            "Epoch 7/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.7958 - val_accuracy: 0.8955\n",
            "Epoch 8/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.8782 - val_accuracy: 0.8990\n",
            "Epoch 9/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.8486 - val_accuracy: 0.8969\n",
            "Epoch 10/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.9138 - val_accuracy: 0.8997\n",
            "Epoch 11/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.9306 - val_accuracy: 0.8969\n",
            "Epoch 12/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 9.2875e-04 - accuracy: 0.9998 - val_loss: 0.9916 - val_accuracy: 0.8976\n",
            "Epoch 13/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 1.0826 - val_accuracy: 0.8990\n",
            "Epoch 14/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 8.0516e-04 - accuracy: 0.9997 - val_loss: 1.0611 - val_accuracy: 0.8976\n",
            "Epoch 15/20\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 6.5226e-04 - accuracy: 0.9998 - val_loss: 1.0463 - val_accuracy: 0.8983\n",
            "Epoch 16/20\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 5.8357e-04 - accuracy: 0.9998 - val_loss: 1.1023 - val_accuracy: 0.8983\n",
            "Epoch 17/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 5.2604e-04 - accuracy: 0.9999 - val_loss: 1.1416 - val_accuracy: 0.8997\n",
            "Epoch 18/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 4.7843e-04 - accuracy: 0.9999 - val_loss: 1.1818 - val_accuracy: 0.8997\n",
            "Epoch 19/20\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 4.4264e-04 - accuracy: 0.9999 - val_loss: 1.2144 - val_accuracy: 0.8997\n",
            "Epoch 20/20\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 4.1259e-04 - accuracy: 0.9999 - val_loss: 1.2465 - val_accuracy: 0.8990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating on our Model\n",
        "\n",
        "While the code above can show our accuracy and loss while we trained for both our train and validation data. We must test it on our test data to check if our model can generalize well. We do this by using the evaluate function and passing it our test data we set aside earlier."
      ],
      "metadata": {
        "id": "gOlhw6DiPVyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Accuracy: ', score[1])"
      ],
      "metadata": {
        "id": "cbT0DKyCoGq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b416b9f3-30b5-447d-ebf7-1793f31d3d9a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9813\n",
            "Accuracy:  0.9813454151153564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating with More Metrics\n",
        "\n",
        "Below we can take the direct probabilities and predictions our model made on the test data. With these we can utilize sklearn's metrics to print our confusion matrix and classification report which highlight how well our model did. Below you can see it has very good sensitivity (detecting that it is not fraud) but not as good specificity (detecting when it is exactly fraud). This was expected and not suprising because of how limited examples our data had for fraudlent aka fake jobs shown by the graph above."
      ],
      "metadata": {
        "id": "SqmkECY2Puek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions so we can calculate more metrics\n",
        "pred = model.predict(x_test)\n",
        "pred_labels = [1 if p>0.5 else 0 for p in pred]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(\"\\nResults on testing data:\\n\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test, pred_labels))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, pred_labels))\n"
      ],
      "metadata": {
        "id": "MWntEnaJoPRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a16c0d-42d2-4d69-ece6-c0ce4f348a67"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111/111 [==============================] - 0s 1ms/step\n",
            "\n",
            "Results on testing data:\n",
            "\n",
            "Confusion Matrix\n",
            "[[3375   10]\n",
            " [  56   97]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      3385\n",
            "           1       0.91      0.63      0.75       153\n",
            "\n",
            "    accuracy                           0.98      3538\n",
            "   macro avg       0.95      0.82      0.87      3538\n",
            "weighted avg       0.98      0.98      0.98      3538\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN\n",
        "\n",
        "RNN are Recurrent Neural Networks and are more complext than the base sequential models such as the one above. There are many different types of RNN and they are usually focused for sequential or time series data. They are often used for stock market prediction, machine translation, and text generation. RNN does this by saving the output of a particular layer and feeding it back to the input to predict the output."
      ],
      "metadata": {
        "id": "--QwlkKkPMPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SimpleRNN\n",
        "\n",
        "Here we build a model with sequential layers but implement embedding and SimpleRNN layers."
      ],
      "metadata": {
        "id": "W83JTtnoaB7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(10000, 32))\n",
        "model.add(layers.SimpleRNN(32))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "-cLQ8aqSqhft"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This summary shows how many parameters will be in each layer. In total there will be 322,113!"
      ],
      "metadata": {
        "id": "3n8G2GhBaPsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "mkddbwhHqjFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364cf103-d394-458e-b38f-769a0b72317c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          320000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322,113\n",
            "Trainable params: 322,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling our SimpleRNN\n",
        "\n",
        "Next we compile just like before! This time we are using the rmsprop optimizer, binary crossentopy for loss and accuracy for metrics."
      ],
      "metadata": {
        "id": "6wJkb9WbaXeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "odSj-XwRqkzj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training our SimpleRNN\n",
        "\n",
        "Next we train just like before, although we have fewer epochs because it will take much longer as well as a slightly larger batch size."
      ],
      "metadata": {
        "id": "-XDgVb4AanaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "id": "mGZJWJKjqmwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcaac4c-887b-4410-ba58-3cb2d4cbec12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/90 [====>.........................] - ETA: 37:27 - loss: 0.1528 - accuracy: 0.9653"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing and Evaluating our SimpleRNN\n",
        "\n",
        "While the code above can show our accuracy and loss while we trained for both our train and validation data. We must test it on our test data to check if our model can generalize well. We do this by using the evaluate function and passing it our test data we set aside earlier."
      ],
      "metadata": {
        "id": "yHI4irmyYJir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "pred = model.predict(x_test)\n",
        "pred = [1.0 if p>= 0.5 else 0.0 for p in pred]\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "L4Yt05Ufqpm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM\n",
        "\n",
        "Here we build a model with sequential layers but implement embedding and LSTM (Long Short-Term Memory) layers. LSTM is another type of RNN."
      ],
      "metadata": {
        "id": "_6olWlAKWDMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(max_features, 32))\n",
        "model.add(layers.LSTM(32))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "WVBSegJjul8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This summary shows how many parameters will be in each layer. In total there will be \\<AMOUNT_HERE\\>!"
      ],
      "metadata": {
        "id": "kCFCVFuIXUld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Re2ZqkH-uopy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling our LSTM\n",
        "\n",
        "Next we compile just like before! We are using the adam optimizer, binary crossentopy for loss and accuracy for metrics just like for SimpleRNN."
      ],
      "metadata": {
        "id": "eXecyk8WXs6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nzwBVoO2urdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training our LSTM\n",
        "\n",
        "Next we train just like before with SimpleRNN."
      ],
      "metadata": {
        "id": "66PlL1KKX7XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data,\n",
        "                    train_labels,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "id": "jz6_hi_Tuual"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing and Evaluating our LSTM\n",
        "\n",
        "While the code above can show our accuracy and loss while we trained for both our train and validation data. We must test it on our test data to check if our model can generalize well. We do this by using the evaluate function and passing it our test data we set aside earlier."
      ],
      "metadata": {
        "id": "fKSCwvx2YflJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(test_data)\n",
        "pred = [1.0 if p>= 0.5 else 0.0 for p in pred]\n",
        "print(classification_report(test_labels, pred))"
      ],
      "metadata": {
        "id": "itgDvmkCuxBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU\n",
        "\n",
        "Here we build a model with sequential layers but implement embedding and GRU(Gated Recurrent Unit) layers. GRU is another type of RNN."
      ],
      "metadata": {
        "id": "ERxrRnnjYkMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(max_features, 32))\n",
        "model.add(layers.GRU(32))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "QtHvWdQkuzNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FnwP7-0pu3A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data,\n",
        "                    train_labels,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "id": "T8L_cwkdu5Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(test_data)\n",
        "pred = [1.0 if p>= 0.5 else 0.0 for p in pred]\n",
        "print(classification_report(test_labels, pred))"
      ],
      "metadata": {
        "id": "PW8ZG3Q3u7_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "BGmnZRz8ZLIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try CNN\n",
        "\n",
        "# build a Sequential model 1D convnet\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(max_features, 128, input_length=maxlen)) \n",
        "model.add(layers.Conv1D(32, 7, activation='relu')) \n",
        "model.add(layers.MaxPooling1D(5)) \n",
        "model.add(layers.Conv1D(32, 7, activation='relu')) \n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "YkB73NFOwmxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "gTSkIWF6vMgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "\n",
        "model.compile(optimizer='adam',  # set learning rate\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pe9WQiO5vM4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "history = model.fit(train_data,\n",
        "                    train_labels,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "id": "dN0HoXOQvPlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "pred = model.predict(test_data)\n",
        "pred = [1.0 if p>= 0.5 else 0.0 for p in pred]\n",
        "print(classification_report(test_labels, pred))"
      ],
      "metadata": {
        "id": "MSGvld5pvUBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try Different Embeddings (BERT, ELMo, etc HuggingFace)"
      ],
      "metadata": {
        "id": "DoI2wQzHwodT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings\n",
        "\n",
        "Here we will try different Embeddings, which are really just pretrained well made models which we can fine-tune for our task. The models we chose for our fake job classification is Distilbert, JobClassifier, and Job-Description-Classifier. These can be found here:\n",
        "\n",
        "[Distilbert](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
        "\n",
        "[JobClassifier](https://huggingface.co/CleveGreen/JobClassifier_v3_gpt)\n",
        "\n",
        "[Job-Description-Classifier](https://huggingface.co/tkuye/job-description-classifier)\n"
      ],
      "metadata": {
        "id": "5-0nwAUHfUP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distilbert\n",
        "\n",
        "Here we will start with Distilbert. We have to load the transformers and tokenizers used by Distilbert. We also loaded the model and the optimizer."
      ],
      "metadata": {
        "id": "yuc5f_a-hSmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the transformers and setup our model and tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "# Setup our tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "# Setup our model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "# Compile our model\n",
        "model.compile(optimizer=optimizer, loss=model.hf_comput_loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7BRZle_zhkIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepping Our Data\n",
        "\n",
        "We have to prep our data for Distilbert specifically using it's tokenizers and convert them into the Tensorflow Dataset Objects"
      ],
      "metadata": {
        "id": "1Lag0V7fjVCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing and Encoding our input text\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding=True)\n",
        "\n",
        "# Creating our Tensorflow Dataset Objects\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_cats\n",
        "))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    val_cats\n",
        "))"
      ],
      "metadata": {
        "id": "bsZVevcyjT08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training and Fine Tuning the Model\n",
        "\n",
        "Here we use fit just like before to fine tune the model to our data set for classifying fake and real jobs."
      ],
      "metadata": {
        "id": "XzPdnODNiuFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset.shuffle(1000).batch(32), epochs=100, batch_size=32,\n",
        "          validation_data=val_dataset.shuffle(1000).batch(32))"
      ],
      "metadata": {
        "id": "_DYOXBKHjIdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating Our Model\n",
        "\n",
        "Here we had to write a for loop to traverse through each test pair, because Bert doesn't have a nice report like sklearn. From there we take the output and increment whether it was a true positive, false positive, false negative, or true negative. From those we can call our print_metrics() function which will calculate and print the confusion matrix, accuracy, sensativity, and specificity."
      ],
      "metadata": {
        "id": "Sfs7oRmYiOBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This evaluates our model by for every test input\n",
        "# From each it will calculate the true positive, false positive, false negative, and true negative\n",
        "# We will use these to calculate the accuracy, confusion matrix, specificity, and sensativity of our model\n",
        "tp, fp, fn, tn = 0\n",
        "for test_data in zip(X_test, y_test):\n",
        "  predict_input = loaded_tokenizer.encode(test_data[0],\n",
        "                                          truncation=True,\n",
        "                                          padding=True,\n",
        "                                          return_tensors=\"tf\")\n",
        "  output = loaded_model(predict_input)[0]\n",
        "  if output >= .5:\n",
        "    predicted = 1\n",
        "  else: \n",
        "    predicted = 0\n",
        "\n",
        "  if predicted == test_data[1] and predicted == 1:\n",
        "    tp += 1\n",
        "  elif predicted != test_data[1] and predicted == 1:\n",
        "    fp += 1\n",
        "  elif predicted == test_data[1] and predicted == 0:\n",
        "    tn += 1\n",
        "  else:\n",
        "    fn += 1\n",
        "  \n",
        "def print_metrics(tp, fp, fn, tn):\n",
        "  # Prints the confusion matrix\n",
        "  print(\"\\nConfusion Matrix:\\n\")\n",
        "  print(tp + \"\\t\" + fp + '\\n' + fn + '\\t' + tn)\n",
        "  print(\"\\nAccuracy: \", (tp+tn)/(tp+fp+fn+tn))\n",
        "  print(\"Sensativity: \", tp/(tp+fn))\n",
        "  print(\"Specificity: \", tn/(fp+tn))\n",
        "\n",
        "# Print out our evaluation metrics\n",
        "print_metrics(tp, fp, fn, tn)\n"
      ],
      "metadata": {
        "id": "YN8zePQRkZ8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JobClassifier\n",
        "\n",
        "Next we will try JobClassifier. We have to load the transformers and tokenizers used by JobClassifier. We also loaded the model and the optimizer."
      ],
      "metadata": {
        "id": "7m6rXDiCjbFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the transformers and setup our model and tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "# Setup our tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"CleveGreen/JobClassifier_v3_gpt\"\n",
        "# Setup our model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"CleveGreen/JobClassifier_v3_gpt\")\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "# Compile our model\n",
        "model.compile(optimizer=optimizer, loss=model.hf_comput_loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vNYYMEVRknto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepping Our Data\n",
        "\n",
        "We have to prep our data for JobClassifier specifically using it's tokenizers and convert them into the Tensorflow Dataset Objects. Just like we did for Distilbert."
      ],
      "metadata": {
        "id": "38clnIl2k8ZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing and Encoding our input text\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding=True)\n",
        "\n",
        "# Creating our Tensorflow Dataset Objects\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_cats\n",
        "))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    val_cats\n",
        "))"
      ],
      "metadata": {
        "id": "8ewFk6sYlIj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training and Fine Tuning the Model\n",
        "\n",
        "Here we use fit just like before to fine tune the model to our data set for classifying fake and real jobs. Just like we did before."
      ],
      "metadata": {
        "id": "z1_eF82rlYnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset.shuffle(1000).batch(32), epochs=100, batch_size=32,\n",
        "          validation_data=val_dataset.shuffle(1000).batch(32))"
      ],
      "metadata": {
        "id": "MiDQoGcIlaui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating Our Model\n",
        "\n",
        "Here we had to write a for loop to traverse through each test pair, because Bert doesn't have a nice report like sklearn. From there we take the output and increment whether it was a true positive, false positive, false negative, or true negative. From those we can call our print_metrics() function which will calculate and print the confusion matrix, accuracy, sensativity, and specificity."
      ],
      "metadata": {
        "id": "2aOqPLATlg90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This evaluates our model by for every test input\n",
        "# From each it will calculate the true positive, false positive, false negative, and true negative\n",
        "# We will use these to calculate the accuracy, confusion matrix, specificity, and sensativity of our model\n",
        "tp, fp, fn, tn = 0\n",
        "for test_data in zip(X_test, y_test):\n",
        "  predict_input = loaded_tokenizer.encode(test_data[0],\n",
        "                                          truncation=True,\n",
        "                                          padding=True,\n",
        "                                          return_tensors=\"tf\")\n",
        "  output = loaded_model(predict_input)[0]\n",
        "  if output >= .5:\n",
        "    predicted = 1\n",
        "  else: \n",
        "    predicted = 0\n",
        "\n",
        "  if predicted == test_data[1] and predicted == 1:\n",
        "    tp += 1\n",
        "  elif predicted != test_data[1] and predicted == 1:\n",
        "    fp += 1\n",
        "  elif predicted == test_data[1] and predicted == 0:\n",
        "    tn += 1\n",
        "  else:\n",
        "    fn += 1\n",
        "  \n",
        "def print_metrics(tp, fp, fn, tn):\n",
        "  # Prints the confusion matrix\n",
        "  print(\"\\nConfusion Matrix:\\n\")\n",
        "  print(tp + \"\\t\" + fp + '\\n' + fn + '\\t' + tn)\n",
        "  print(\"\\nAccuracy: \", (tp+tn)/(tp+fp+fn+tn))\n",
        "  print(\"Sensativity: \", tp/(tp+fn))\n",
        "  print(\"Specificity: \", tn/(fp+tn))\n",
        "\n",
        "# Print out our evaluation metrics\n",
        "print_metrics(tp, fp, fn, tn)\n"
      ],
      "metadata": {
        "id": "UenDQsO6lhuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Job-Description-Classifier\n",
        "\n",
        "Finally we will try Job-Description-Classifier. We have to load the transformers and tokenizers used by Job-Description-Classifier. We also loaded the model and the optimizer."
      ],
      "metadata": {
        "id": "jQQOaJi4l8AS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the transformers and setup our model and tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "# Setup our tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"tkuye/job-description-classifier\")\n",
        "# Setup our model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"tkuye/job-description-classifier\")\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "# Compile our model\n",
        "model.compile(optimizer=optimizer, loss=model.hf_comput_loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2tyXN_2-mO0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepping Our Data\n",
        "\n",
        "We have to prep our data for Job-Description-Classifier specifically using it's tokenizers and convert them into the Tensorflow Dataset Objects. Just like we did for Distilbert and JobClassifier."
      ],
      "metadata": {
        "id": "OP340AN0oFCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing and Encoding our input text\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding=True)\n",
        "\n",
        "# Creating our Tensorflow Dataset Objects\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_cats\n",
        "))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    val_cats\n",
        "))"
      ],
      "metadata": {
        "id": "M4qrhh8colM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training and Fine Tuning the Model\n",
        "\n",
        "Here we use fit just like before to fine tune the model to our data set for classifying fake and real jobs. Just like we did before."
      ],
      "metadata": {
        "id": "sJwvVlkzpaN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset.shuffle(1000).batch(32), epochs=100, batch_size=32,\n",
        "          validation_data=val_dataset.shuffle(1000).batch(32))"
      ],
      "metadata": {
        "id": "qz_F_ZxGpe8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating Our Model\n",
        "\n",
        "Here we had to write a for loop to traverse through each test pair, because Bert doesn't have a nice report like sklearn. From there we take the output and increment whether it was a true positive, false positive, false negative, or true negative. From those we can call our print_metrics() function which will calculate and print the confusion matrix, accuracy, sensativity, and specificity."
      ],
      "metadata": {
        "id": "yJVXmLVQpjYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This evaluates our model by for every test input\n",
        "# From each it will calculate the true positive, false positive, false negative, and true negative\n",
        "# We will use these to calculate the accuracy, confusion matrix, specificity, and sensativity of our model\n",
        "tp, fp, fn, tn = 0\n",
        "for test_data in zip(X_test, y_test):\n",
        "  predict_input = loaded_tokenizer.encode(test_data[0],\n",
        "                                          truncation=True,\n",
        "                                          padding=True,\n",
        "                                          return_tensors=\"tf\")\n",
        "  output = loaded_model(predict_input)[0]\n",
        "  if output >= .5:\n",
        "    predicted = 1\n",
        "  else: \n",
        "    predicted = 0\n",
        "\n",
        "  if predicted == test_data[1] and predicted == 1:\n",
        "    tp += 1\n",
        "  elif predicted != test_data[1] and predicted == 1:\n",
        "    fp += 1\n",
        "  elif predicted == test_data[1] and predicted == 0:\n",
        "    tn += 1\n",
        "  else:\n",
        "    fn += 1\n",
        "  \n",
        "def print_metrics(tp, fp, fn, tn):\n",
        "  # Prints the confusion matrix\n",
        "  print(\"\\nConfusion Matrix:\\n\")\n",
        "  print(tp + \"\\t\" + fp + '\\n' + fn + '\\t' + tn)\n",
        "  print(\"\\nAccuracy: \", (tp+tn)/(tp+fp+fn+tn))\n",
        "  print(\"Sensativity: \", tp/(tp+fn))\n",
        "  print(\"Specificity: \", tn/(fp+tn))\n",
        "\n",
        "# Print out our evaluation metrics\n",
        "print_metrics(tp, fp, fn, tn)"
      ],
      "metadata": {
        "id": "QNbyW3i2pp8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze Perfomance of all"
      ],
      "metadata": {
        "id": "eWPLVJxzwrFj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}