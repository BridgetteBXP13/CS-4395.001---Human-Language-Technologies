{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363a7ca4-a513-4d28-94cf-a2b39509368c",
   "metadata": {},
   "source": [
    "# WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5325ddcf-d462-40f4-b399-1792fd15a94b",
   "metadata": {},
   "source": [
    "## By: Bridgette Bryant (NetID: BMB180001), for CS 4395.001 Human Language Technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b36ee6-208c-4a36-b133-7bb3204a8bee",
   "metadata": {},
   "source": [
    "### WordNet: \n",
    "WordNet was started/organized as a project by George Miller at Princeton University. It's goal was to support theories of human semantic memory which suggested that people organize concepts mentally in some sort of hierarchy. WordNet is now a lexical database of nouns, verbs, adjectives, and adverbs which provides short definitions (called glosses) and examples. WordNet uses synsets, which are synonym sets for each word. Theses synsets have the following relations:\n",
    "\n",
    "- hypernym (higher): a plant is a hypernym of tree\n",
    "- hyponym (lower): a tree is a hyponym of plant\n",
    "- meronym (part of): graphics card is a meronym of computer\n",
    "- holonym (whole): computer is a holonym of graphics card\n",
    "- troponym (more specific action): stealthy is a troponym of walk\n",
    "\n",
    "Keep in mind not all synset lemmas will have an entry for every relation above, the nouns are the most connected compared to other types of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca75eb-85e1-4629-859e-a348ae0b0d01",
   "metadata": {},
   "source": [
    "### Importing Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51260e89-2761-4a9a-b637-3200fb868c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# Import the wordnet library from nltk corpus\n",
    "from nltk.corpus import wordnet as wn\n",
    "# Import the lesk algorithm from nltk wsd\n",
    "from nltk.wsd import lesk\n",
    "# Import the SentiWordNet library from nltk corpus\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "# Import the text4 from the nltk book library\n",
    "from nltk.book import text4\n",
    "# Import the library math from python\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a6efc-acb5-475b-9221-7086d22cbe0b",
   "metadata": {},
   "source": [
    "### Displaying Synsets of a Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f1952e-7ede-422a-912e-b6dfe010893d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('turtleneck.n.01'),\n",
       " Synset('turtle.n.02'),\n",
       " Synset('capsize.v.01'),\n",
       " Synset('turtle.v.02')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is a an example of selecting a noun and displaying all synsets.\n",
    "# I chose turtle.\n",
    "wn.synsets('turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2d9847-f925-452d-856c-98e11b761a79",
   "metadata": {},
   "source": [
    "### Noun Synset's Information, Hierarchy, and Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab6a34-60c6-4f3a-8a0a-2223dec41ec9",
   "metadata": {},
   "source": [
    "#### Displaying Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7d8b0a-af89-4408-b7e8-22f3c1a8042d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'any of various aquatic and land reptiles having a bony shell and flipper-like limbs for swimming'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the turtle synset's definition\n",
    "wn.synset('turtle.n.02').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f569aceb-b932-4ecc-bb3b-d215c3b99370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the turtle synset's examples\n",
    "wn.synset('turtle.n.02').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25866aec-4772-49c0-8496-66f81a579d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('turtle.n.02.turtle')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the turtle synset's lemmas\n",
    "wn.synset('turtle.n.02').lemmas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8580dc55-acd0-4b61-a97b-2e71cf5ffcb9",
   "metadata": {},
   "source": [
    "#### Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a3e7cc4-d15c-4eed-8ca0-99a4430c58c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chelonian.n.01'),\n",
       " Synset('anapsid.n.01'),\n",
       " Synset('reptile.n.01'),\n",
       " Synset('vertebrate.n.01'),\n",
       " Synset('chordate.n.01'),\n",
       " Synset('animal.n.01'),\n",
       " Synset('organism.n.01'),\n",
       " Synset('living_thing.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('object.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traverse through the Hierarchy from synset\n",
    "snake = wn.synset('turtle.n.02')\n",
    "hyper = lambda s: s.hypernyms()\n",
    "list(snake.closure(hyper))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b1ef9-859d-49fb-92c0-d1c79c280331",
   "metadata": {},
   "source": [
    "#### Wordnet Hierarchy Organization\n",
    "The wordnet hierarchy seems to move up one classification or umbrella term. For example looking at the turtle noun synset hierarchy above, we go from turtle to anapsid, to reptile, to vertebrate, and eventually all the away to entity. I think it could be a good way of getting umbrella and word classification for words as it is very organized and simple to traverse through."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e6b9bd-670e-4d92-a191-049e428e0811",
   "metadata": {},
   "source": [
    "#### Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78543bc-280f-4b19-b8ed-55acb8844dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chelonian.n.01')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To output hypernyms for the turtle synset\n",
    "wn.synset('turtle.n.02').hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "122aafb6-0d13-4917-be57-f41862c0f6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('box_turtle.n.01'),\n",
       " Synset('cooter.n.01'),\n",
       " Synset('mud_turtle.n.01'),\n",
       " Synset('painted_turtle.n.01'),\n",
       " Synset('red-bellied_terrapin.n.01'),\n",
       " Synset('sea_turtle.n.01'),\n",
       " Synset('slider.n.03'),\n",
       " Synset('snapping_turtle.n.01'),\n",
       " Synset('soft-shelled_turtle.n.01'),\n",
       " Synset('terrapin.n.01'),\n",
       " Synset('tortoise.n.01')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To output hyponyms for the turtle synset\n",
    "wn.synset('turtle.n.02').hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c758f480-9b99-48b2-b463-fb0f87902185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('carapace.n.01'), Synset('plastron.n.05')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To output meronyms for the turtle synset\n",
    "wn.synset('turtle.n.02').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9ecb568-fbcc-41e5-aaf6-6a4062b19958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To output holonyms for the turtle synset\n",
    "wn.synset('turtle.n.02').part_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d842fd15-3173-4eac-b434-900a99f87597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To output antonyms for the snake synset\n",
    "wn.synset('turtle.n.02').lemmas()[0].antonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731bc5e1-3ffd-4118-8597-70793ff7a04a",
   "metadata": {},
   "source": [
    "### Displaying Synsets of a Verb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea40e66-9598-45ee-b256-e9f0ff9a1c26",
   "metadata": {},
   "source": [
    "### Verb Synset's Information and Hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c071230-01da-48de-a489-111c28b04181",
   "metadata": {},
   "source": [
    "#### Displaying Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30e277b9-db58-49f7-8904-d75f58561ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('walk.n.01'),\n",
       " Synset('base_on_balls.n.01'),\n",
       " Synset('walk.n.03'),\n",
       " Synset('walk.n.04'),\n",
       " Synset('walk.n.05'),\n",
       " Synset('walk.n.06'),\n",
       " Synset('walk_of_life.n.01'),\n",
       " Synset('walk.v.01'),\n",
       " Synset('walk.v.02'),\n",
       " Synset('walk.v.03'),\n",
       " Synset('walk.v.04'),\n",
       " Synset('walk.v.05'),\n",
       " Synset('walk.v.06'),\n",
       " Synset('walk.v.07'),\n",
       " Synset('walk.v.08'),\n",
       " Synset('walk.v.09'),\n",
       " Synset('walk.v.10')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is a an example of selecting a verb and displaying all synsets.\n",
    "# I chose walk.\n",
    "wn.synsets('walk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c834078-3aa9-4814-aa5c-645f35a15da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"use one's feet to advance; advance by steps\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the walk synset's definition\n",
    "wn.synset('walk.v.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32f29edb-ba1f-472a-b4d5-abebf447ad0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Walk, don't run!\",\n",
       " 'We walked instead of driving',\n",
       " 'She walks with a slight limp',\n",
       " 'The patient cannot walk yet',\n",
       " 'Walk over to the cabinet']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the walk synset's examples\n",
    "wn.synset('walk.v.01').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e8171e0-f906-4285-b304-ff615df588d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('walk.v.01.walk')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the walk synset's examples\n",
    "wn.synset('walk.v.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8c1669-0b0c-4ba2-a90a-d1243f92c68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('travel.v.01')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traverse through the Hierarchy from synset\n",
    "walk = wn.synset('walk.v.01')\n",
    "hyper = lambda s: s.hypernyms()\n",
    "list(walk.closure(hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a96ca32-8f63-498b-9982-688e0104eb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is what happends when we traverse through travel\n",
    "walk = wn.synset('travel.v.01')\n",
    "hyper = lambda s: s.hypernyms()\n",
    "list(walk.closure(hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d622ae4-ea7f-437d-80b6-329d685f5ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('gesticulate.v.01'),\n",
       " Synset('communicate.v.02'),\n",
       " Synset('interact.v.01'),\n",
       " Synset('act.v.01')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is traversing the Hierarchy from synset for wave as a verb to get more output\n",
    "wave = wn.synset('wave.v.01')\n",
    "hyper = lambda s: s.hypernyms()\n",
    "list(wave.closure(hyper))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610ad8de-3a03-4ceb-878c-8a449f528887",
   "metadata": {},
   "source": [
    "#### Wordnet Hierarchy Organization\n",
    "The wordnet hierarchy for verbs is not as robust as nouns and don't have a top level synset (like entity.n.01). For example looking at the wave verb synset hierarchy above, we go from wave to gesticulate, to communicate, to interact, and eventually all the away to act. Whereas the walk verb synset only had travel. I think it could be a good way of getting umbrella and word classification for words as it is very organized and simple to traverse through. But it is much more limited that than the nouns and that should be accounted for that not all verbs will neccessarily have a hierarchy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f6298-0a71-4020-b9f2-de784f93e06f",
   "metadata": {},
   "source": [
    "### Morphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b3090ca-528b-42ce-8221-2bcc5505d944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using morphy to find as many different forms of the word walk as possible\n",
    "wn.morphy('walk', wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a322127-f482-460f-87fc-35adc2e9a405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.morphy('walks', wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d713708-30fc-4557-b3b6-5495b83dfcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.morphy('walk', wn.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f662512-5126-4e8a-9057-5f62af230111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.morphy('walks', wn.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ee92468-55d9-4edb-b490-a7a81eed0201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.morphy('walked', wn.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac84d2c5-060c-4cae-8ab2-a00316faa98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.morphy('walking', wn.VERB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367fd51b-adf8-4b52-86f1-8f026834b41d",
   "metadata": {},
   "source": [
    "## Similarities Between Words\n",
    "I have choosen words turtle and snake, which are very similar. Below I have choosen the animal-based synsets. Run the Wu-Palmer similarity metric and Lesk algorithm. Write a couple sentences with your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56a522f2-d574-4608-8c16-b31d9b42be19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('turtleneck.n.01'),\n",
       " Synset('turtle.n.02'),\n",
       " Synset('capsize.v.01'),\n",
       " Synset('turtle.v.02')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the synset for turtle\n",
    "wn.synsets(\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "429ba5fd-b901-49d7-815a-0771471e6060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'any of various aquatic and land reptiles having a bony shell and flipper-like limbs for swimming'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing the sysnset 'turtle.n.02'\n",
    "wn.synset('turtle.n.02').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25845f36-4eae-4a40-a8c4-1ed4740c0409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('snake.n.01'),\n",
       " Synset('snake.n.02'),\n",
       " Synset('snake.n.03'),\n",
       " Synset('hydra.n.02'),\n",
       " Synset('snake.n.05'),\n",
       " Synset('snake.v.01'),\n",
       " Synset('snake.v.02'),\n",
       " Synset('snake.v.03')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the synset for snake\n",
    "wn.synsets(\"snake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b58c7d33-f374-47a1-9eff-55d3dacaf187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'limbless scaly elongate reptile; some are venomous'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing the sysnset 'snake.n.01'\n",
    "wn.synset('snake.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a414d531-681a-4814-abf8-133398033cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the WordNet similarity to see how similar the two synsets are\n",
    "wn.path_similarity(wn.synset('turtle.n.02'),wn.synset('snake.n.01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb0df3-390e-4067-af55-cc24f8162254",
   "metadata": {},
   "source": [
    "### Wu-Palmer Similarity Metric\n",
    "Running the Wu-Palmer similarity metric on the turtle and tortoise synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19301bdc-81e6-4551-8700-220df9782517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the WordNet Wu-Palmer simularity metric to see how similar the two synsets are\n",
    "wn.wup_similarity(wn.synset('turtle.n.02'),wn.synset('snake.n.01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc6f7f-d4cb-4d4b-8e53-eaa41a6958e8",
   "metadata": {},
   "source": [
    "### Lesk Algorithm\n",
    "Running the Lesk Algorithm on the turtle and snake synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d52551c-3593-4a10-82f8-c2949b8d9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a function which takes a string and prints all the definitions \n",
    "# For all the found synsets in WordNet\n",
    "def getDef(s):\n",
    "    for syn in wn.synsets(str(s)):\n",
    "        print(syn, syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "610bd9b6-bfb1-426f-a75e-7117799b6efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('turtleneck.n.01') a sweater or jersey with a high close-fitting collar\n",
      "Synset('turtle.n.02') any of various aquatic and land reptiles having a bony shell and flipper-like limbs for swimming\n",
      "Synset('capsize.v.01') overturn accidentally\n",
      "Synset('turtle.v.02') hunt for turtles, especially as an occupation\n"
     ]
    }
   ],
   "source": [
    "# We will look at the definitions for turtle using our function above\n",
    "getDef(\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4aa3c25d-2d72-4b01-8d60-b3ae7a644755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('snake.n.01') limbless scaly elongate reptile; some are venomous\n",
      "Synset('snake.n.02') a deceitful or treacherous person\n",
      "Synset('snake.n.03') a tributary of the Columbia River that rises in Wyoming and flows westward; discovered in 1805 by the Lewis and Clark Expedition\n",
      "Synset('hydra.n.02') a long faint constellation in the southern hemisphere near the equator stretching between Virgo and Cancer\n",
      "Synset('snake.n.05') something long, thin, and flexible that resembles a snake\n",
      "Synset('snake.v.01') move smoothly and sinuously, like a snake\n",
      "Synset('snake.v.02') form a snake-like pattern\n",
      "Synset('snake.v.03') move along a winding path\n"
     ]
    }
   ],
   "source": [
    "# We will look at the definitions for snake using our function above\n",
    "getDef(\"snake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fc69cb1-21c2-499e-9ea9-1ea7e87c53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a few sentences to run the algorithm on\n",
    "sent1 = ['There', 'is', 'a', 'wrinkle', 'in', 'my', 'turtleneck', '.']\n",
    "sent2 = ['There', 'is', 'a', 'turtle', 'in', 'my', 'yard', '.']\n",
    "sent3 = ['I', 'turtled', 'over', 'my', 'car', '.']\n",
    "sent4 = ['Those', 'crazy', 'poachers', 'keep', 'going', 'turtling', 'in', 'our', 'pond', '!']\n",
    "sent5 = ['There', 'is', 'a', 'snake', 'in', 'my', 'yard', '.']\n",
    "sent6 = ['That', 'snake', 'stole', 'some', 'money', 'again', '!']\n",
    "sent7 = ['Do', 'you', 'know', 'about', 'the', 'snake', 'river', '?']\n",
    "sent8 = ['Can', 'you', 'see', 'the', 'snake', 'in', 'the', 'stars', '?']\n",
    "sent9 = ['I', 'bought', 'this', 'new', 'drain', 'snake', 'I', 'saw', 'on', 'TV', '.']\n",
    "sent10 = ['He', 'can', 'easily', 'snake', 'through', 'the', 'muddy', 'water', '.']\n",
    "sent11 = ['They', 'snake', 'around', 'the', 'yard', '.']\n",
    "sent12 = ['The', 'hiking', 'trail', 'snakes', 'along', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a7f8a8b-ccc4-4c87-a609-661f00a59cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('turtleneck.n.01')\n"
     ]
    }
   ],
   "source": [
    "# Testing the Lesk Algorithm on the different sentences\n",
    "print(lesk(sent1, 'turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5196c188-5328-4c88-8fd3-60164c39a731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('turtleneck.n.01')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent2, 'turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b70a3d93-b2b9-403c-b449-378a28b8ca64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('turtleneck.n.01')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent3, 'turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c92b9498-0222-4c41-9df4-aa28368d3959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('turtleneck.n.01')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent4, 'turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c2a9758-fc40-446e-bcfe-8a4bed523766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('snake.v.01')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent5, 'snake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3076ab7-eac3-46b8-9fbd-00e331152f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('snake.v.01')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent6, 'snake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ed0d70a-45a3-4cc7-8082-0f0818a7f2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('snake.v.01')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent7, 'snake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2eb9d80d-d0fd-4dc0-baaf-933c9ad18f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('snake.n.03')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent8, 'snake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "124e62b3-3ba6-4353-995d-0e7375f34faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('snake.v.01')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent9, 'snake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c1ca9e5-cf86-49dd-88d0-97f21b7be1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('snake.v.01')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent10, 'snake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e57735c-5e73-41e5-9aa2-8ad039440740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('snake.v.01')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent11, 'snake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d345ff8-5d24-419f-ae77-830eb59879da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('snake.v.03')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent12, 'snake'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3696b060-78c5-4d19-83c1-16786f8f9d64",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "The Wu-Palmer algorithm was very effective at seeing the similarity between turtle and snake. Especially when compared to the path similarity.\n",
    "\n",
    "The Lesk algorithm performed very horribly on the turtle synset, as it only got 1 out of 4 sentences correct. It also performed terribly on the snake synset as it got 1 out of 8 sentences correct. Personally, I believe the correct ones were by chance and the algorithm really seemed to struggle with the difference in nouns. I found this quite interesting and humorous, if I added more parameters it might have helped. I suppose the synsets snaked their way through the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8db5ac7-c282-40a0-88b4-1472e81870ad",
   "metadata": {},
   "source": [
    "## SentiWordNet\n",
    "\n",
    "SentiWordNet builds upon WordNet's synset resources and adds opinion attibutes to words/sentences. They all have 3 sentiment scores for each synset, positivity, negativity, and objectivity. The sum of all 3 scores will always equate to 1, and they can only be imbetween values 0 and 1 (just like a percentage). SentiWordNet could be used to attempt to read tone of the text's emotions, detect abuse/bullying/toxic behavior, or possibly spam (which is usually filled with emotionally charged and urgent words)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a9e2d-b2e7-462c-bdaf-1b5d07711196",
   "metadata": {},
   "source": [
    "### SentiWordNet with Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b93d8f82-17df-4c2a-b5bc-a3185c18144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have written a function to print polarity scores of a given sent_synset\n",
    "def printScores(sent_syn):\n",
    "    try:\n",
    "        print(sent_syn)\n",
    "        print(\"Positive Score = \", sent_syn.pos_score())\n",
    "        print(\"Negative Score = \", sent_syn.neg_score())\n",
    "        print(\"Objective Score = \", sent_syn.obj_score())\n",
    "    except:\n",
    "        print(\"Not a sent_synset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67ef391b-1c19-4d1c-b610-b7541947e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have written a function to get scores of a given synset\n",
    "def getScores(w):\n",
    "    try:\n",
    "        word = swn.senti_synset(w)\n",
    "        # Calling the printScores function\n",
    "        printScores(word)\n",
    "    except:\n",
    "        print(\"Not a synset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4b7e5a8-1fef-433b-be26-2a2228eadeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hate.v.01: PosScore=0.0 NegScore=0.75>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.75\n",
      "Objective Score =  0.25\n"
     ]
    }
   ],
   "source": [
    "# I have selected the emotionally charged word 'hate'\n",
    "# Using my getScores function from above\n",
    "getScores(\"hate.v.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "342571e9-16d4-4710-8489-f6654d5cb94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<love.v.01: PosScore=0.5 NegScore=0.0>\n",
      "Positive Score =  0.5\n",
      "Negative Score =  0.0\n",
      "Objective Score =  0.5\n"
     ]
    }
   ],
   "source": [
    "# I have selected the emotionally charged word 'hate'\n",
    "# Using my getScores function from above\n",
    "getScores(\"love.v.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "988ee1de-53ff-44a6-b4af-d5622115d752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<passionate.a.01: PosScore=0.375 NegScore=0.375>\n",
      "Positive Score =  0.375\n",
      "Negative Score =  0.375\n",
      "Objective Score =  0.25\n"
     ]
    }
   ],
   "source": [
    "# I have selected the emotionally charged word 'hate'\n",
    "# Using my getScores function from above\n",
    "getScores(\"passionate.a.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c587e84-f778-4f6f-b789-8bc818c0e723",
   "metadata": {},
   "source": [
    "### SentiWordNet with Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3716acf1-15f1-48f5-82f8-b2895a193030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wrote some sentences to try with SentiWordNet\n",
    "sent1 = \"I hated that terrible car it was always breaking down!\"\n",
    "sent2 = \"That book had so much love in it I just had to keep reading.\"\n",
    "sent3 = \"He was very passionate about his job, but I do not think he loved it.\"\n",
    "sent4 = \"People are always so quick to hate a new good thing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0061a32-2b2d-45b4-b10e-c3e0c9bec043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function to output the polarity for each word given a sentence\n",
    "def sentPolarity(sent):\n",
    "    try:\n",
    "        # Split the sentence in to word tokens\n",
    "        tokens = sent.split()\n",
    "        # For each word token in the tokens list\n",
    "        for token in tokens:\n",
    "            # Create list of possible matching synsets for the current token\n",
    "            syn_list = list(swn.senti_synsets(token))\n",
    "            if syn_list:\n",
    "                # Print the name and score of the current token\n",
    "                print(token)\n",
    "                printScores(syn_list[0])\n",
    "                print()\n",
    "                \n",
    "\n",
    "    except:\n",
    "        print(\"Something went wrong, with sentPolarity function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbf9b7d3-2f5c-454d-8d0d-8e0f5a33e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function to calculate the polarity sum given a sentence\n",
    "def sentPolaritySum(sent):\n",
    "    negSum = 0\n",
    "    posSum = 0\n",
    "    try:\n",
    "        # Split the sentence in to word tokens\n",
    "        tokens = sent.split()\n",
    "        # For each word token in the tokens list\n",
    "        for token in tokens:\n",
    "            # Create list of possible matching synsets for the current token\n",
    "            syn_list = list(swn.senti_synsets(token))\n",
    "            if syn_list:\n",
    "                # For the current senti_syn \n",
    "                cur_syn = syn_list[0]\n",
    "                # Add the negative to the sum\n",
    "                negSum += cur_syn.neg_score()\n",
    "                # Add the positive to the sum\n",
    "                posSum += cur_syn.pos_score()\n",
    "    \n",
    "        print(\"Sentence:\\n\", sent)\n",
    "        print(\"Negative Score = \", negSum)\n",
    "        print(\"Positive Score = \", posSum)\n",
    "\n",
    "                \n",
    "\n",
    "    except:\n",
    "        print(\"Something went wrong, with sentPolaritySum function!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc7b842-a7a8-4ac2-99b2-9e9cac3e02c1",
   "metadata": {},
   "source": [
    "#### Sentence 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdda8947-fe27-43a6-a197-50a7c0280c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "<iodine.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "hated\n",
      "<hate.v.01: PosScore=0.0 NegScore=0.75>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.75\n",
      "Objective Score =  0.25\n",
      "\n",
      "terrible\n",
      "<awful.s.02: PosScore=0.0 NegScore=0.625>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.625\n",
      "Objective Score =  0.375\n",
      "\n",
      "car\n",
      "<car.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "it\n",
      "<information_technology.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "was\n",
      "<washington.n.02: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "always\n",
      "<always.r.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "breaking\n",
      "<breakage.n.03: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the function to get the scores of each word in our sentence\n",
    "sentPolarity(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd39289c-e2db-43d4-915e-f0e5fa964597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:\n",
      " I hated that terrible car it was always breaking down!\n",
      "Negative Score =  1.375\n",
      "Positive Score =  0.0\n"
     ]
    }
   ],
   "source": [
    "# Use the function to get the sum of the scores for each word in our sentence\n",
    "sentPolaritySum(sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984a235-c25c-4ae3-afc5-85e6798f829a",
   "metadata": {},
   "source": [
    "#### Sentence 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b078346-e6e3-4331-b188-cda46fdc8ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book\n",
      "<book.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "had\n",
      "<have.v.01: PosScore=0.25 NegScore=0.0>\n",
      "Positive Score =  0.25\n",
      "Negative Score =  0.0\n",
      "Objective Score =  0.75\n",
      "\n",
      "so\n",
      "<sol.n.03: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "much\n",
      "<much.n.01: PosScore=0.125 NegScore=0.125>\n",
      "Positive Score =  0.125\n",
      "Negative Score =  0.125\n",
      "Objective Score =  0.75\n",
      "\n",
      "love\n",
      "<love.n.01: PosScore=0.625 NegScore=0.0>\n",
      "Positive Score =  0.625\n",
      "Negative Score =  0.0\n",
      "Objective Score =  0.375\n",
      "\n",
      "in\n",
      "<inch.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "it\n",
      "<information_technology.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "I\n",
      "<iodine.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "just\n",
      "<just.a.01: PosScore=0.625 NegScore=0.0>\n",
      "Positive Score =  0.625\n",
      "Negative Score =  0.0\n",
      "Objective Score =  0.375\n",
      "\n",
      "had\n",
      "<have.v.01: PosScore=0.25 NegScore=0.0>\n",
      "Positive Score =  0.25\n",
      "Negative Score =  0.0\n",
      "Objective Score =  0.75\n",
      "\n",
      "keep\n",
      "<support.n.06: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the function to get the scores of each word in our sentence\n",
    "sentPolarity(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fa98f3e-c0b0-4755-891c-cbde964c48ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:\n",
      " That book had so much love in it I just had to keep reading.\n",
      "Negative Score =  0.125\n",
      "Positive Score =  1.875\n"
     ]
    }
   ],
   "source": [
    "# Use the function to get the sum of the scores for each word in our sentence\n",
    "sentPolaritySum(sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799407e-8b05-4997-a07d-26c70cdf2859",
   "metadata": {},
   "source": [
    "#### Sentence 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1fc5bd8d-bd43-4d5e-a005-250fabafcfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "<helium.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "was\n",
      "<washington.n.02: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "very\n",
      "<very.s.01: PosScore=0.5 NegScore=0.0>\n",
      "Positive Score =  0.5\n",
      "Negative Score =  0.0\n",
      "Objective Score =  0.5\n",
      "\n",
      "passionate\n",
      "<passionate.a.01: PosScore=0.375 NegScore=0.375>\n",
      "Positive Score =  0.375\n",
      "Negative Score =  0.375\n",
      "Objective Score =  0.25\n",
      "\n",
      "about\n",
      "<about.s.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "but\n",
      "<merely.r.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "I\n",
      "<iodine.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "do\n",
      "<bash.n.02: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "not\n",
      "<not.r.01: PosScore=0.0 NegScore=0.625>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.625\n",
      "Objective Score =  0.375\n",
      "\n",
      "think\n",
      "<think.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "he\n",
      "<helium.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "loved\n",
      "<love.v.01: PosScore=0.5 NegScore=0.0>\n",
      "Positive Score =  0.5\n",
      "Negative Score =  0.0\n",
      "Objective Score =  0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the function to get the scores of each word in our sentence\n",
    "sentPolarity(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8d5e16f-0471-4a9c-bd8e-d6d81a538d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:\n",
      " He was very passionate about his job, but I do not think he loved it.\n",
      "Negative Score =  1.0\n",
      "Positive Score =  1.375\n"
     ]
    }
   ],
   "source": [
    "# Use the function to get the sum of the scores for each word in our sentence\n",
    "sentPolaritySum(sent3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec5d36b-b450-4c69-a66e-716154cf6fca",
   "metadata": {},
   "source": [
    "#### Sentence 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cf7fa20-e514-4e57-8b14-2c45460ce1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People\n",
      "<people.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "are\n",
      "<are.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "always\n",
      "<always.r.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "so\n",
      "<sol.n.03: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "quick\n",
      "<quick.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "hate\n",
      "<hate.n.01: PosScore=0.125 NegScore=0.375>\n",
      "Positive Score =  0.125\n",
      "Negative Score =  0.375\n",
      "Objective Score =  0.5\n",
      "\n",
      "a\n",
      "<angstrom.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score =  0.0\n",
      "Negative Score =  0.0\n",
      "Objective Score =  1.0\n",
      "\n",
      "new\n",
      "<new.a.01: PosScore=0.375 NegScore=0.0>\n",
      "Positive Score =  0.375\n",
      "Negative Score =  0.0\n",
      "Objective Score =  0.625\n",
      "\n",
      "good\n",
      "<good.n.01: PosScore=0.5 NegScore=0.0>\n",
      "Positive Score =  0.5\n",
      "Negative Score =  0.0\n",
      "Objective Score =  0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the function to get the scores of each word in our sentence\n",
    "sentPolarity(sent4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78414131-bcc8-42da-8141-af32ae814491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:\n",
      " People are always so quick to hate a new good thing.\n",
      "Negative Score =  0.375\n",
      "Positive Score =  1.0\n"
     ]
    }
   ],
   "source": [
    "# Use the function to get the sum of the scores for each word in our sentence\n",
    "sentPolaritySum(sent4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c39b74e-de8f-4854-b72f-35990f589216",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Overall for how simple the processing is I think for most uses SentWordNet does a good job of labeling words/phrases as positive and negative. However, it does have it's limitations and doesn't handle context heavy sentences very well. As far as uses it could easily be used to detect spam or toxic/bullying in chats, emails, and other text based messaging systems. It could possibly detect extreme reviews as well (good or bad) such as for Google/Amazon product reviews to filter out automated or exaggerated responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2737f4-3ed3-40d8-bc49-736ff15b8fde",
   "metadata": {},
   "source": [
    "## Collocation\n",
    "Collocations are words which appear together forming a greater meaning than by themselves. As an example the phrase 'dead person' has much more meaning than either words 'dead' or 'person' by themselves. It is common for phrases and titles to be collocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59ca2c3d-74f8-4ade-bed0-2dc90b5ab0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n"
     ]
    }
   ],
   "source": [
    "# Here is the output of collocations of text4 from nltk.book\n",
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a8e1b-4434-4ccf-9013-e975aa3020bf",
   "metadata": {},
   "source": [
    "### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eaec0e0a-43fa-4309-ba00-ba5193c3fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have selected 'Inidian tribes' to calculate mutual information on\n",
    "# Holds the text4 tokens\n",
    "text = ' '.join(text4.tokens)\n",
    "# Holds the total number of vocabulary in text4\n",
    "vocab = len(set(text4))\n",
    "# Holds the p(Inidian Tribes) (the count/vocab of the collocation)\n",
    "indTrb = text.count('Indian tribes')/vocab\n",
    "# Holds the p(Indian) (the count/vocab of just Indian)\n",
    "ind = text.count('Indian')/vocab\n",
    "# Holds the p(tribes) (the count/vocab of just tribes\n",
    "trb = text.count('tribes')/vocab\n",
    "# Calculates the pmi ( log ( (P(x,y)) / (P(x) * P(y)) ) )\n",
    "pmi = math.log2(indTrb / (ind * trb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1d93da8-498d-4750-a97f-e43a7b0c33d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p('Indian tribes') =  0.000598503740648379\n",
      "p('Indian') =  0.0010972568578553616\n",
      "p('tribes') =  0.000598503740648379\n",
      "pmi =  9.831882997592349\n"
     ]
    }
   ],
   "source": [
    "# Prints our mutual calculation results\n",
    "print(\"p('Indian tribes') = \", indTrb)\n",
    "print(\"p('Indian') = \", ind)\n",
    "print(\"p('tribes') = \", trb)\n",
    "print(\"pmi = \", pmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5575fb2-724e-4ca7-bcab-905ecad2d30b",
   "metadata": {},
   "source": [
    "The results above show a PMI of 9 which is fairly high and positive, this implies the that 'Indian tribes' is likely to be a collocation. I agree with this output as 'Indian tribes' is a collocation as 'Indian' and 'tribes' by themeselves don't give the same/as meaningful meaning as 'Indian tribes'. If the result was close to 0 it would imply they are independent, if it was negative it would imply they are not a collocation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
